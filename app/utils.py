import time
import uuid
from datetime import datetime
from typing import Any, Dict, List

from fastapi import WebSocket


class MemoryStore:
    """Global memory storage for uploaded files and chat history"""

    def __init__(self):
        self.uploaded_files: List[Dict[str, Any]] = []
        self.chat_history: Dict[str, List[Dict[str, Any]]] = {}
        self.has_memory: bool = False
        self.session_id: str = str(uuid.uuid4())

    def reset(self, chat_id: str = None):
        """Reset the chat session and clear memory"""
        if chat_id:
            # Reset specific chat
            if chat_id in self.chat_history:
                del self.chat_history[chat_id]
        else:
            # Reset all chats
            self.chat_history = {}
            # Generate new session ID only if resetting all chats
            self.session_id = str(uuid.uuid4())

        self.has_memory = len(self.chat_history) > 0

    def create_chat(self) -> str:
        """Create a new chat session and return the chat_id"""
        chat_id = str(uuid.uuid4())
        self.chat_history[chat_id] = []
        return chat_id

    def add_chat(
        self, question: str, answer: str, source: str = "", chat_id: str = None
    ):
        """Add a chat entry to the history"""
        # If no chat_id provided, create a new one or use default
        if not chat_id:
            if not self.chat_history:
                chat_id = self.create_chat()
            else:
                # Use the first available chat_id as default
                chat_id = list(self.chat_history.keys())[0]

        # Create chat if it doesn't exist
        if chat_id not in self.chat_history:
            self.chat_history[chat_id] = []

        chat_entry = {
            "id": str(uuid.uuid4()),
            "question": question,
            "answer": answer,
            "source": source,
            "timestamp": datetime.now().isoformat(),
            "chat_id": chat_id,
        }

        self.chat_history[chat_id].append(chat_entry)
        self.has_memory = True
        return chat_entry

    def get_chat_history(self, chat_id: str) -> List[Dict[str, Any]]:
        """Get chat history for a specific chat_id"""
        return self.chat_history.get(chat_id, [])

    def get_all_chats(self) -> Dict[str, List[Dict[str, Any]]]:
        """Get all chat histories"""
        return self.chat_history

    def get_total_chat_count(self) -> int:
        """Get total number of chat messages across all chats"""
        return sum(len(messages) for messages in self.chat_history.values())

    def get_chat_sessions_count(self) -> int:
        """Get number of chat sessions"""
        return len(self.chat_history)


class ConnectionManager:
    """WebSocket connection manager for streaming chat"""

    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        """Accept and store a new WebSocket connection"""
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        """Remove a WebSocket connection"""
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)


def mock_pdf_qa(question: str, uploaded_files: List[Dict]) -> tuple[str, str]:
    """
    Mock function to simulate PDF content analysis and question answering.
    In a real implementation, this would use LLM/AI to process PDFs and answer questions.
    """
    if not uploaded_files:
        return (
            "I don't have any documents to reference. Please upload some PDFs first.",
            "",
        )

    time.sleep(0.5)

    question_lower = question.lower()

    if "summary" in question_lower or "summarize" in question_lower:
        answer = (
            f"Based on the uploaded document(s), here's a summary: "
            "The documents contain information relevant to your query. This is a mock response"
            f"simulating content analysis from {len(uploaded_files)} uploaded file(s)."
        )
        source = uploaded_files[0]["filename"] if uploaded_files else ""
    elif "what" in question_lower or "how" in question_lower or "why" in question_lower:
        answer = (
            f"According to the uploaded documents, here's what I found: {question} - "
            "This is a simulated response that would typically be generated by analyzing "
            "the PDF content using AI/LLM."
        )
        source = uploaded_files[-1]["filename"] if uploaded_files else ""
    else:
        answer = (
            f"I found relevant information in your documents regarding: '{question}'. "
            "This response is generated from the uploaded PDF content analysis simulation."
        )
        source = (
            f"Multiple sources ({len(uploaded_files)} files)"
            if len(uploaded_files) > 1
            else (uploaded_files[0]["filename"] if uploaded_files else "")
        )

    return answer, source
